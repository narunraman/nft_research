{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32a3c491-3743-49cb-95e2-08ce75cd342e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from more_itertools import chunked\n",
    "from psql_methods import execute_commands\n",
    "from Openseas_Methods import *\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "from pymongo import MongoClient\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import psql_methods as psql\n",
    "from IPython.display import display\n",
    "import os\n",
    "import pandas as pd\n",
    "import alchemy_methods as alc\n",
    "from image_utils import pull_image_from_url\n",
    "import multiprocessing\n",
    "skip_list=['ens','base-introduced','fundrop-pass','gemesis','apecoin','dai-stablecoin','uniswap','1inch-token']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d21fccb",
   "metadata": {},
   "source": [
    "This notebook was use to increase the number of unique tokens for each collection in the snob effect analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "557a58c6-50cd-4716-a9b4-40f058e996c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "snob_df = pd.read_pickle('snob_effect_nfts.pkl')\n",
    "snob_slugs = tuple(snob_df['Collection'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bd2c014-03c7-4593-bdcf-224fd3f292fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = [f\"select * from nfttoimage where slug in {snob_slugs}\"]\n",
    "rows  = execute_commands(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "893b4558-dda6-48cb-a09c-c9456498af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rows)\n",
    "# Convert the list of tuples to a DataFrame\n",
    "tuple_df = pd.DataFrame(rows, columns=['Collection', 'NFT_num', 'url'])\n",
    "snob_df['NFT_num'] = snob_df['NFT_num'].astype(int)\n",
    "# Merge the DataFrames to find tuples not already in df\n",
    "merged_df = pd.merge(tuple_df, snob_df, on=['Collection', 'NFT_num'], how='left', indicator=True)\n",
    "\n",
    "# Filter the tuples that are not in df\n",
    "not_in_df = merged_df[merged_df['_merge'] == 'left_only'].drop('_merge', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "660b8736-fc23-4832-8337-8f4a6745a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_rows(group):\n",
    "    if len(group) >= 300:\n",
    "        return group.sample(300)\n",
    "    else:\n",
    "        return group\n",
    "sampled_df = not_in_df.groupby('Collection', group_keys=False).apply(sample_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "216019f9-6ded-4fe6-a309-aeb3196477f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = sampled_df.groupby('Collection').apply(lambda x: (x['Collection'].iloc[0], list(zip(x['NFT_num'], x['url']))))\n",
    "args = list(grouped_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2645e28-b443-41af-8a79-3cf80d509339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/scratch/tlundy/NFT_Research/nft_venv/lib/python3.8/site-packages/PIL/Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/global/scratch/tlundy/NFT_Research/nft_venv/lib/python3.8/site-packages/PIL/Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/global/scratch/tlundy/NFT_Research/nft_venv/lib/python3.8/site-packages/PIL/Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/global/scratch/tlundy/NFT_Research/nft_venv/lib/python3.8/site-packages/PIL/Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/global/scratch/tlundy/NFT_Research/nft_venv/lib/python3.8/site-packages/PIL/Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/global/scratch/tlundy/NFT_Research/nft_venv/lib/python3.8/site-packages/PIL/Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/global/scratch/tlundy/NFT_Research/nft_venv/lib/python3.8/site-packages/PIL/Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/global/scratch/tlundy/NFT_Research/nft_venv/lib/python3.8/site-packages/PIL/Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "num_processes = multiprocessing.cpu_count()\n",
    "with multiprocessing.Pool(processes=num_processes) as pool: # Use all cores   \n",
    "    for result in pool.starmap(pull_image_from_url, args):\n",
    "        records.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc61bffb-afea-4734-828c-8f4da7b2e43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = [\"SELECT * from collectiontoaddress\"]\n",
    "data = psql.execute_commands(commands)\n",
    "slug_to_contract = {x[0]:x[1] for x in data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab3e4138-335e-4649-8e11-beaac703fb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377797\n"
     ]
    }
   ],
   "source": [
    "sampled_df['Contract'] = sampled_df['Collection'].map(slug_to_contract)\n",
    "selected_columns = sampled_df[['Contract', 'NFT_num']].to_numpy().tolist()\n",
    "print(len(selected_columns))\n",
    "sales_grab = list(chunked(selected_columns,10_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45508ef-567d-4422-bfcd-8a75de808b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 10000/10000 [33:31<00:00,  4.97it/s]\n",
      " 16%|███████▎                                       | 1557/10000 [05:07<24:49,  5.67it/s]"
     ]
    }
   ],
   "source": [
    "for sale_chunk in sales_grab:\n",
    "    sales = alc.NFT_to_sales(sale_chunk)\n",
    "    commands = []\n",
    "    data_list = []\n",
    "    command = \"INSERT INTO nfttosales_2 (contract, token_id, sale_price) VALUES (%s, %s, %s) returning token_id\"\n",
    "    for sale in sales:\n",
    "        commands.append(command)\n",
    "        data_list.append(sale)\n",
    "    psql.execute_commands(commands,data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb03ea94-fc64-4d22-9a4d-7c02a25d6903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nft_venv",
   "language": "python",
   "name": "nft_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
