{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90a64061-ce74-47ff-971f-da8cac51a62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import feature_extract\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import torch\n",
    "import pandas as pd\n",
    "import psql_methods as psql\n",
    "import pickle\n",
    "import alchemy_methods as alc\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle\n",
    "import image_utils as imgs\n",
    "from Openseas_Methods import pull_nft_images,pull_nft_contracts\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50c5288a-747e-4b7d-9bf1-c903e130706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First step is loading the list of distinct NFT slugs that present in the graph dataset\n",
    "with open('../Graph_predictions/dataset_stor/graph_dataset_4/label_list.pkl','rb') as f:\n",
    "    label_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db78fcaf-04ca-46cb-afa6-b7a3f7dd4544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second step is to pull all of the NFT collections that already have entries in the DB\n",
    "commands = [\"SELECT distinct slug from nfttoimage\"]\n",
    "data = psql.execute_commands(commands)\n",
    "data = [x[0] for x in data]\n",
    "#Figure out which labels still need to find URLs for\n",
    "nfts_to_process = [x for x in label_list if x not in data]\n",
    "len(nfts_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39834bf4-1a17-4796-81d2-66085ce42f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull contracts as well incase we need to use alchemy API\n",
    "contract_check = tuple(nfts_to_process)\n",
    "commands = [\"SELECT * from collectiontoaddress\"]\n",
    "data = psql.execute_commands(commands)\n",
    "data_dict = {x[0]:x[1] for x in data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5b449a-8271-46b9-9011-32e90e13f7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nft_w_contract = [(x,data_dict.get(x,None)) for x in nfts_to_process]\n",
    "slugs_no_contract = [x[0] for x in nft_w_contract if x[1] is None]\n",
    "# for slug in tqdm(slugs_no_contract):\n",
    "#     pull_nft_contracts(slug)\n",
    "len(slugs_no_contract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1989e002-8053-47ce-8d19-f973cd3ed68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull 500 NFT URLs from openseas api per slug with no data\n",
    "import logging\n",
    "logging.basicConfig(filename='slug_url_logs.txt', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "for slug,_ in tqdm(nft_w_contract):\n",
    "    logging.info(f\"Beginning slug {slug}\")\n",
    "    data.append(pull_nft_images(slug,limit_toks=500))\n",
    "    logging.info(f\"Finished slug {slug}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92bee168-a270-4679-96a5-789dedfb84f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check out old dataset to see which NFTs already have images\n",
    "file_path = 'images/val'\n",
    "complete_nfts = get_immediate_subdirectories(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f7faa3-af4e-46b7-af1a-9243e0e21ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subselect 50 NFTs per collection to get images of\n",
    "images_to_pull = [x for x in label_list if x not in complete_nfts]\n",
    "images_to_pull = tuple(images_to_pull)\n",
    "command = [\"\"\"WITH numbered_rows AS (\n",
    "  SELECT *,\n",
    "         ROW_NUMBER() OVER (PARTITION BY slug ORDER BY RANDOM()) AS row_num\n",
    "  FROM nfttoimage\n",
    ")\n",
    "SELECT *\n",
    "FROM numbered_rows\n",
    "WHERE row_num <= 50;\"\"\"]\n",
    "rows  = psql.execute_commands(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b9a85a9-3e10-4413-8a20-6d9e710ea3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "417326"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove row number field\n",
    "rows_to_pull = [(x[0],x[1],x[2]) for x in rows if x[0] in images_to_pull]\n",
    "len(rows_to_pull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38300032-4f0b-44e5-a2aa-4aab4c1c88c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411294\n",
      "28412\n"
     ]
    }
   ],
   "source": [
    "#If you need to restart half way run this cell to not redo collections that are done\n",
    "file_path = 'graph_images/val'\n",
    "complete_nfts = get_immediate_subdirectories(file_path)\n",
    "print(len(rows_to_pull))\n",
    "rows_to_pull = [x for x in rows_to_pull if x[0] not in complete_nfts]\n",
    "print(len(rows_to_pull))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b4eacf9-fc90-498e-8b55-1215f4dabbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restructure data into format for multiprocessing\n",
    "# Column names for the DataFrame\n",
    "columns = ['slug', 'token_id', 'url']\n",
    "\n",
    "# Create a DataFrame from the list of tuples\n",
    "df = pd.DataFrame(rows_to_pull, columns=columns)\n",
    "grouped_data = df.groupby('slug').apply(lambda x: (x['slug'].iloc[0], list(zip(x['token_id'], x['url']))))\n",
    "args = list(grouped_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "501d8e51-7b30-4f0b-9779-40d560bdfb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/scratch/tlundy/NFT_Research/nft_venv/lib/python3.8/site-packages/PIL/Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/global/scratch/tlundy/NFT_Research/nft_venv/lib/python3.8/site-packages/PIL/Image.py:3182: DecompressionBombWarning: Image size (114545795 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "/global/scratch/tlundy/NFT_Research/nft_venv/lib/python3.8/site-packages/PIL/Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/global/scratch/tlundy/NFT_Research/nft_venv/lib/python3.8/site-packages/PIL/Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/global/scratch/tlundy/NFT_Research/nft_venv/lib/python3.8/site-packages/PIL/Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/global/scratch/tlundy/NFT_Research/nft_venv/lib/python3.8/site-packages/PIL/Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/global/scratch/tlundy/NFT_Research/nft_venv/lib/python3.8/site-packages/PIL/Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/global/scratch/tlundy/NFT_Research/nft_venv/lib/python3.8/site-packages/PIL/Image.py:3182: DecompressionBombWarning: Image size (100000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "/global/scratch/tlundy/NFT_Research/nft_venv/lib/python3.8/site-packages/PIL/Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/global/scratch/tlundy/NFT_Research/nft_venv/lib/python3.8/site-packages/PIL/Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#This is the cell that spawns processes and retreives images also creates log files for tracking\n",
    "records = []\n",
    "num_processes = multiprocessing.cpu_count()\n",
    "with multiprocessing.Pool(processes=num_processes) as pool: # Use all cores   \n",
    "    for result in pool.starmap(pull_image_from_url, args):\n",
    "        records.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "394f03e7-b715-43fc-ac62-a9bc7473e8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete empty directories for collections for which the image retrieveal failed for some reason\n",
    "imgs.delete_empty_directories(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b175f27-4c92-478b-98b4-186c9b135147",
   "metadata": {},
   "source": [
    "Next step is to run the feature extract notebook on the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "272a84c6-ee6a-4bb8-8056-1cd4efb12fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ReturnIndexDataset\n",
      "    Number of datapoints: 456144\n",
      "    Root location: /global/scratch/tlundy/NFT_Research/nft_research/Dino/graph_images/val\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Features</th>\n",
       "      <th>Collection</th>\n",
       "      <th>NFT_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.006129133980721235, 0.08498869091272354, -0...</td>\n",
       "      <td>-glowa-</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.04774976521730423, 0.05362828075885773, 0.0...</td>\n",
       "      <td>-glowa-</td>\n",
       "      <td>10017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.10529650747776031, 0.07033471018075943, 0.0...</td>\n",
       "      <td>-glowa-</td>\n",
       "      <td>10018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[-0.02233046293258667, 0.01190363708883524, -0...</td>\n",
       "      <td>-glowa-</td>\n",
       "      <td>10019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.04859286919236183, 0.054554957896471024, 0....</td>\n",
       "      <td>-glowa-</td>\n",
       "      <td>10024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456139</th>\n",
       "      <td>10976</td>\n",
       "      <td>[-0.033141832798719406, -0.0350814163684845, -...</td>\n",
       "      <td>zzz-zzz-by-hashlips</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456140</th>\n",
       "      <td>10976</td>\n",
       "      <td>[-0.033141832798719406, -0.0350814163684845, -...</td>\n",
       "      <td>zzz-zzz-by-hashlips</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456141</th>\n",
       "      <td>10976</td>\n",
       "      <td>[-0.033141832798719406, -0.0350814163684845, -...</td>\n",
       "      <td>zzz-zzz-by-hashlips</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456142</th>\n",
       "      <td>10976</td>\n",
       "      <td>[-0.033141832798719406, -0.0350814163684845, -...</td>\n",
       "      <td>zzz-zzz-by-hashlips</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456143</th>\n",
       "      <td>10976</td>\n",
       "      <td>[-0.033141832798719406, -0.0350814163684845, -...</td>\n",
       "      <td>zzz-zzz-by-hashlips</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>456144 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Label                                           Features  \\\n",
       "0           0  [0.006129133980721235, 0.08498869091272354, -0...   \n",
       "1           0  [0.04774976521730423, 0.05362828075885773, 0.0...   \n",
       "2           0  [0.10529650747776031, 0.07033471018075943, 0.0...   \n",
       "3           0  [-0.02233046293258667, 0.01190363708883524, -0...   \n",
       "4           0  [0.04859286919236183, 0.054554957896471024, 0....   \n",
       "...       ...                                                ...   \n",
       "456139  10976  [-0.033141832798719406, -0.0350814163684845, -...   \n",
       "456140  10976  [-0.033141832798719406, -0.0350814163684845, -...   \n",
       "456141  10976  [-0.033141832798719406, -0.0350814163684845, -...   \n",
       "456142  10976  [-0.033141832798719406, -0.0350814163684845, -...   \n",
       "456143  10976  [-0.033141832798719406, -0.0350814163684845, -...   \n",
       "\n",
       "                 Collection NFT_num  \n",
       "0                   -glowa-       1  \n",
       "1                   -glowa-   10017  \n",
       "2                   -glowa-   10018  \n",
       "3                   -glowa-   10019  \n",
       "4                   -glowa-   10024  \n",
       "...                     ...     ...  \n",
       "456139  zzz-zzz-by-hashlips      75  \n",
       "456140  zzz-zzz-by-hashlips      77  \n",
       "456141  zzz-zzz-by-hashlips      78  \n",
       "456142  zzz-zzz-by-hashlips      79  \n",
       "456143  zzz-zzz-by-hashlips       8  \n",
       "\n",
       "[456144 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We assume the features have already been computed by the feature_extract_notebook\n",
    "model_string = 'dinov2_vits14'\n",
    "data_path = '/global/scratch/tlundy/NFT_Research/nft_research/Dino/graph_images'\n",
    "out_path = f'/global/scratch/tlundy/NFT_Research/nft_research/Dino/graph_images_features/{model_string}'\n",
    "feature_path = out_path+'/testfeat.pth'\n",
    "features = torch.load(feature_path)\n",
    "labels = feature_extract.get_labels(data_path)\n",
    "file_names = feature_extract.get_filenames(data_path)\n",
    "features_list = features.tolist()\n",
    "# Create a pandas DataFrame\n",
    "data = {'Label': labels.tolist(), 'Features': features_list,'Collection':[x[0] for x in file_names],\n",
    "        'NFT_num':[x[1] for x in file_names]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7214d4d-18a0-4fbc-aac5-d3f133613101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 10977/10977 [00:06<00:00, 1793.75it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "# Group the DataFrame by 'Label'\n",
    "grouped = df.groupby('Label')\n",
    "\n",
    "# Compute average feature vector for each label\n",
    "average_feature_vectors = []\n",
    "for label, group in tqdm(grouped):\n",
    "    # Compute average feature vector for the current label\n",
    "    avg_feature_vector = np.mean(group['Features'].tolist(), axis=0)\n",
    "    average_feature_vectors.append((label, avg_feature_vector))\n",
    "average_features_df = pd.DataFrame(average_feature_vectors, columns=['Label', 'AverageFeatureVector'])\n",
    "merged_df2 = pd.merge(df, average_features_df, on='Label')\n",
    "merged_df2.to_pickle('graph_images_dataframe.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d746848-f108-41b6-b38d-18411ae77cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nft_venv",
   "language": "python",
   "name": "nft_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
