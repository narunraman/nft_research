{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1301ecb4-93b9-4ccb-b17c-2d308e7cb0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from psql_methods import execute_commands\n",
    "from Openseas_Methods import *\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "from pymongo import MongoClient\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from IPython.display import display\n",
    "import os\n",
    "import pandas as pd\n",
    "from image_utils import pull_image_from_url\n",
    "import multiprocessing\n",
    "skip_list=['ens','base-introduced','fundrop-pass','gemesis','apecoin','dai-stablecoin','uniswap','1inch-token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d5ae86b-709f-4026-9f74-351e6360b462",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = [\"select * from nfttoimage where slug='boredapeyachtclub'\"]\n",
    "rows  = execute_commands(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "228af4d0-b3f3-4189-ab60-294cbb1daa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names for the DataFrame\n",
    "columns = ['slug', 'token_id', 'url']\n",
    "\n",
    "# Create a DataFrame from the list of tuples\n",
    "df = pd.DataFrame(rows, columns=columns)\n",
    "grouped_data = df.groupby('slug').apply(lambda x: (x['slug'].iloc[0], list(zip(x['token_id'], x['url']))))\n",
    "args = list(grouped_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a506ac00-28bb-4642-9e9c-5fd4f3f58184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/scratch/tlundy/NFT_Research/nft_venv/lib/python3.8/site-packages/PIL/Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "num_processes = multiprocessing.cpu_count()\n",
    "with multiprocessing.Pool(processes=num_processes) as pool: # Use all cores   \n",
    "    for result in pool.starmap(pull_image_from_url, args):\n",
    "        records.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857c49cd-b5b9-42e4-9d7f-a136fa8ac880",
   "metadata": {},
   "source": [
    "# After previous step run feature_extract on newly generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dc39e4f-6cbd-49b9-88eb-f32789252f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ReturnIndexDataset\n",
      "    Number of datapoints: 10000\n",
      "    Root location: /global/scratch/tlundy/NFT_Research/nft_research/Dino/embedding_test/val\n",
      "('boredapeyachtclub', '0')\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "#We assume the features have already been computed by the feature_extract_notebook\n",
    "# model = torch.hub.load('facebookresearch/dino:main', 'dino_vits8')\n",
    "import feature_extract\n",
    "import torch\n",
    "model_string = 'dinov2_vits14'\n",
    "\n",
    "data_path = '/global/scratch/tlundy/NFT_Research/nft_research/Dino/embedding_test'\n",
    "out_path = f'/global/scratch/tlundy/NFT_Research/nft_research/Dino/embedding_test_features/{model_string}'\n",
    "feature_path = out_path+'/testfeat.pth'\n",
    "features = torch.load(feature_path)\n",
    "labels = feature_extract.get_labels(data_path)\n",
    "file_names = feature_extract.get_filenames(data_path)\n",
    "print(file_names[0])\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50d09218-70e0-4816-9909-f0c5b0be41ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = features.tolist()\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "data = {'Label': labels.tolist(), 'Features': features_list,'Collection':[x[0] for x in file_names],\n",
    "        'NFT_num':[x[1] for x in file_names]}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e6db113d-306f-4754-bdb2-eaf12cc9a4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_vector(vector):\n",
    "    magnitude = np.linalg.norm(vector)\n",
    "    if magnitude != 0:\n",
    "        return vector / magnitude\n",
    "    else:\n",
    "        return vector\n",
    "df['norm_features'] = df['Features'].apply(normalize_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e977baef-7a21-489a-b6a6-978054b7f16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████▍          | 8/10 [00:43<00:10,  5.02s/it]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "# Group the DataFrame by 'Label'\n",
    "\n",
    "\n",
    "# Compute average feature vector for each label\n",
    "column = 'norm_features'\n",
    "true_vec = np.mean(df[column].tolist(), axis=0)\n",
    "true_dists = [np.linalg.norm(true_vec - np.array(row[column])) for _, row in df.iterrows()]\n",
    "avg_true_dists = sum(true_dists)/len(true_dists)\n",
    "num_samples = 10\n",
    "sizes = [5000,2500,500,250,50,25,10,5]\n",
    "afvs = []\n",
    "for x in tqdm(range(0,num_samples)):\n",
    "    samples = []\n",
    "    samples.append(avg_true_dists)\n",
    "    for size in sizes:\n",
    "        sampled_rows = df.sample(size)   \n",
    "        # Compute average feature vector for the current label\n",
    "        avg_feature_vector = np.mean(sampled_rows[column].tolist(), axis=0)\n",
    "        dist = [np.linalg.norm(avg_feature_vector - np.array(row[column])) for _, row in df.iterrows()]\n",
    "        gaps = [abs(x-y) for x, y in zip(true_dists, dist)]\n",
    "        avg_dist = sum(gaps)/len(gaps)\n",
    "        samples.append(avg_dist)\n",
    "    afvs.append(samples)\n",
    "df_2 = pd.DataFrame(afvs,columns=['True Dists']+sizes)\n",
    "# print(average_feature_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d1cbf4cd-2967-42c9-beb7-c7258ad4cd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Dists</th>\n",
       "      <th>5000</th>\n",
       "      <th>2500</th>\n",
       "      <th>500</th>\n",
       "      <th>250</th>\n",
       "      <th>50</th>\n",
       "      <th>25</th>\n",
       "      <th>10</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.778930e-01</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>0.005057</td>\n",
       "      <td>0.010519</td>\n",
       "      <td>0.017335</td>\n",
       "      <td>0.031062</td>\n",
       "      <td>0.048217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.121495e-16</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>0.004666</td>\n",
       "      <td>0.008757</td>\n",
       "      <td>0.014084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.778930e-01</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.002545</td>\n",
       "      <td>0.005411</td>\n",
       "      <td>0.010176</td>\n",
       "      <td>0.017307</td>\n",
       "      <td>0.024886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.778930e-01</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.003966</td>\n",
       "      <td>0.008606</td>\n",
       "      <td>0.013878</td>\n",
       "      <td>0.023917</td>\n",
       "      <td>0.039018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.778930e-01</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>0.003107</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>0.010076</td>\n",
       "      <td>0.016359</td>\n",
       "      <td>0.028424</td>\n",
       "      <td>0.048513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.778930e-01</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.003649</td>\n",
       "      <td>0.005870</td>\n",
       "      <td>0.011725</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>0.037386</td>\n",
       "      <td>0.055822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.778930e-01</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>0.005901</td>\n",
       "      <td>0.009988</td>\n",
       "      <td>0.019036</td>\n",
       "      <td>0.026887</td>\n",
       "      <td>0.060459</td>\n",
       "      <td>0.098381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         True Dists       5000       2500        500        250         50  \\\n",
       "count  5.000000e+01  50.000000  50.000000  50.000000  50.000000  50.000000   \n",
       "mean   4.778930e-01   0.000752   0.001235   0.003197   0.005057   0.010519   \n",
       "std    1.121495e-16   0.000243   0.000312   0.000893   0.001701   0.002785   \n",
       "min    4.778930e-01   0.000432   0.000642   0.001524   0.002545   0.005411   \n",
       "25%    4.778930e-01   0.000604   0.001035   0.002600   0.003966   0.008606   \n",
       "50%    4.778930e-01   0.000671   0.001150   0.003107   0.004611   0.010076   \n",
       "75%    4.778930e-01   0.000856   0.001472   0.003649   0.005870   0.011725   \n",
       "max    4.778930e-01   0.001438   0.002027   0.005901   0.009988   0.019036   \n",
       "\n",
       "              25         10          5  \n",
       "count  50.000000  50.000000  50.000000  \n",
       "mean    0.017335   0.031062   0.048217  \n",
       "std     0.004666   0.008757   0.014084  \n",
       "min     0.010176   0.017307   0.024886  \n",
       "25%     0.013878   0.023917   0.039018  \n",
       "50%     0.016359   0.028424   0.048513  \n",
       "75%     0.021053   0.037386   0.055822  \n",
       "max     0.026887   0.060459   0.098381  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f377ac13-169a-417b-bea4-1df2e8a25e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[f'distance_10000'] = [np.linalg.norm(afvs[0][1] - np.array(row['Features'])) for _, row in df.iterrows()]\n",
    "for size,vec in afvs[1:]:\n",
    "    df[f'loss_{size}'] = abs(df[f'distance_10000']-[np.linalg.norm(vec - np.array(row['Features'])) for _, row in df.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f797076-9b3f-4a63-b366-384088a0946b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>distance_10000</th>\n",
       "      <th>loss_5000</th>\n",
       "      <th>loss_2500</th>\n",
       "      <th>loss_500</th>\n",
       "      <th>loss_250</th>\n",
       "      <th>loss_50</th>\n",
       "      <th>loss_25</th>\n",
       "      <th>loss_10</th>\n",
       "      <th>loss_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.477893</td>\n",
       "      <td>9.172778e-04</td>\n",
       "      <td>2.233007e-03</td>\n",
       "      <td>0.003327</td>\n",
       "      <td>3.818623e-03</td>\n",
       "      <td>0.017389</td>\n",
       "      <td>1.689231e-02</td>\n",
       "      <td>0.034215</td>\n",
       "      <td>0.033327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071173</td>\n",
       "      <td>6.098213e-04</td>\n",
       "      <td>1.494059e-03</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>2.575069e-03</td>\n",
       "      <td>0.011481</td>\n",
       "      <td>1.261625e-02</td>\n",
       "      <td>0.021775</td>\n",
       "      <td>0.019976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.324956</td>\n",
       "      <td>2.003225e-07</td>\n",
       "      <td>8.270743e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>6.733999e-07</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>9.724327e-07</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.424306</td>\n",
       "      <td>3.933704e-04</td>\n",
       "      <td>1.017917e-03</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>1.670476e-03</td>\n",
       "      <td>0.007795</td>\n",
       "      <td>6.482333e-03</td>\n",
       "      <td>0.016472</td>\n",
       "      <td>0.016797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.465317</td>\n",
       "      <td>8.403242e-04</td>\n",
       "      <td>2.015564e-03</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>3.481500e-03</td>\n",
       "      <td>0.015880</td>\n",
       "      <td>1.419889e-02</td>\n",
       "      <td>0.031829</td>\n",
       "      <td>0.032276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.521787</td>\n",
       "      <td>1.388247e-03</td>\n",
       "      <td>3.217001e-03</td>\n",
       "      <td>0.004877</td>\n",
       "      <td>5.639650e-03</td>\n",
       "      <td>0.025887</td>\n",
       "      <td>2.523632e-02</td>\n",
       "      <td>0.049248</td>\n",
       "      <td>0.047857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.786557</td>\n",
       "      <td>2.868575e-03</td>\n",
       "      <td>6.699363e-03</td>\n",
       "      <td>0.011305</td>\n",
       "      <td>1.295937e-02</td>\n",
       "      <td>0.051817</td>\n",
       "      <td>6.047855e-02</td>\n",
       "      <td>0.103424</td>\n",
       "      <td>0.097707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label  distance_10000     loss_5000     loss_2500      loss_500  \\\n",
       "count  10000.0    10000.000000  1.000000e+04  1.000000e+04  10000.000000   \n",
       "mean       0.0        0.477893  9.172778e-04  2.233007e-03      0.003327   \n",
       "std        0.0        0.071173  6.098213e-04  1.494059e-03      0.002304   \n",
       "min        0.0        0.324956  2.003225e-07  8.270743e-07      0.000001   \n",
       "25%        0.0        0.424306  3.933704e-04  1.017917e-03      0.001420   \n",
       "50%        0.0        0.465317  8.403242e-04  2.015564e-03      0.002951   \n",
       "75%        0.0        0.521787  1.388247e-03  3.217001e-03      0.004877   \n",
       "max        0.0        0.786557  2.868575e-03  6.699363e-03      0.011305   \n",
       "\n",
       "           loss_250       loss_50       loss_25       loss_10        loss_5  \n",
       "count  1.000000e+04  10000.000000  1.000000e+04  10000.000000  10000.000000  \n",
       "mean   3.818623e-03      0.017389  1.689231e-02      0.034215      0.033327  \n",
       "std    2.575069e-03      0.011481  1.261625e-02      0.021775      0.019976  \n",
       "min    6.733999e-07      0.000006  9.724327e-07      0.000049      0.000006  \n",
       "25%    1.670476e-03      0.007795  6.482333e-03      0.016472      0.016797  \n",
       "50%    3.481500e-03      0.015880  1.419889e-02      0.031829      0.032276  \n",
       "75%    5.639650e-03      0.025887  2.523632e-02      0.049248      0.047857  \n",
       "max    1.295937e-02      0.051817  6.047855e-02      0.103424      0.097707  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099280a0-e114-479e-bdef-605f03f4147b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nft_venv",
   "language": "python",
   "name": "nft_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
